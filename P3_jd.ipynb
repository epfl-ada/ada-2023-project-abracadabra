{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    " \n",
    "import P3_helpers as hlp\n",
    "from P3_helpers import get_dataframe, get_parsed_comment, get_LDA_model, tokenize_one_comment, get_LDA_model_from_saved_file\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and preprocessing DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Source', 'Target', 'Vote', 'Results', 'Year', 'Date', 'Comment'], dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_dataframe()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Parsed_Comment'] = df['Comment'].apply(get_parsed_comment)\n",
    "df['Tokenized_Comment_not_filtered'] = df['Parsed_Comment'].apply(tokenize_one_comment)\n",
    "df['BoW'] = hlp.get_bow_column(df['Tokenized_Comment_not_filtered'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing and saving topic models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_topics: 3\n",
      "Saving model for 3 topics\n",
      "Topic_3 done\n",
      "nb_topics: 5\n",
      "Saving model for 5 topics\n",
      "Topic_5 done\n",
      "nb_topics: 7\n",
      "Saving model for 7 topics\n",
      "Topic_7 done\n",
      "nb_topics: 9\n",
      "Saving model for 9 topics\n",
      "Topic_9 done\n"
     ]
    }
   ],
   "source": [
    "isTrainSession = False\n",
    "\n",
    "if isTrainSession:\n",
    "    comments_series = df['Parsed_Comment'].copy(deep=True)\n",
    "    topic_range = range(3, 10, 2)\n",
    "    for nb_topics in topic_range:\n",
    "        print(f\"nb_topics: {nb_topics}\")\n",
    "        lda = get_LDA_model(comments_series=comments_series, num_topics=nb_topics)\n",
    "        print(f\"Saving model for {nb_topics} topics\")\n",
    "        lda.save(fname=f\"lda_model_{nb_topics}_all_true_lda\")\n",
    "        print(f\"Topic_{nb_topics} done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading pre-computed models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "nb_topics = range(3, 10, 2)\n",
    "\n",
    "for nb_topic in nb_topics:\n",
    "    models.append(get_LDA_model_from_saved_file(f\"./topic_model_states_dict/lda_model_{nb_topic}_all_true_lda\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infer Topics by Comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, model in enumerate(models):\n",
    "    df[f'Topics_from_{nb_topics[i]}'] = df['BoW'].apply(model.get_document_topics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_save = False\n",
    "if new_save:\n",
    "    df.to_csv('df_with_topics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, model in enumerate(models):\n",
    "    d = model.print_topics(num_words=15)\n",
    "    d = {topic[0]:topic[1] for topic in d}\n",
    "    with open(f\"topics_{nb_topics[i]}_dict.json\", 'w') as f:\n",
    "        json.dump(d,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "# Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Source', 'Target', 'Vote', 'Results', 'Year', 'Date', 'Comment',\n",
       "       'Parsed_Comment', 'Tokenized_Comment_not_filtered', 'BoW',\n",
       "       'Topics_from_3', 'Topics_from_5', 'Topics_from_7', 'Topics_from_9'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = hlp.get_df_with_topics_from_csv()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Parsed_Comment', 'BoW', 'Topics_from_3', 'Topics_from_5', 'Topics_from_7', 'Topics_from_9']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Parsed_Comment', 'BoW', 'Topics_from_3', 'Topics_from_5',\n",
       "       'Topics_from_7', 'Topics_from_9', 'Topics_from_3_first_topic',\n",
       "       'Topics_from_3_first_topic_prob', 'Topics_from_3_second_topic',\n",
       "       'Topics_from_3_second_topic_prob', 'Topics_from_5_first_topic',\n",
       "       'Topics_from_5_first_topic_prob', 'Topics_from_5_second_topic',\n",
       "       'Topics_from_5_second_topic_prob', 'Topics_from_7_first_topic',\n",
       "       'Topics_from_7_first_topic_prob', 'Topics_from_7_second_topic',\n",
       "       'Topics_from_7_second_topic_prob', 'Topics_from_9_first_topic',\n",
       "       'Topics_from_9_first_topic_prob', 'Topics_from_9_second_topic',\n",
       "       'Topics_from_9_second_topic_prob'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_topics = range(3, 10, 2)\n",
    "topic_positions = ['first', 'second']\n",
    "\n",
    "for t_number in nb_topics:\n",
    "    for pos in topic_positions:\n",
    "        df[f'Topics_from_{t_number}_'+pos+'_topic'] = df[f'Topics_from_{t_number}'].apply(lambda x: x[0][0])\n",
    "        df[f'Topics_from_{t_number}_'+pos+'_topic_prob'] = df[f'Topics_from_{t_number}'].apply(lambda x: x[0][1])\n",
    "\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_dict = hlp.get_stats_dict_from_df_with_topics(df, nb_topics=nb_topics, topic_positions=topic_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(3,\n",
       "  'first'):    Topic  count  mean_prob_when_first_pos  std_prob_when_first_pos  \\\n",
       " 0      0  96938                  0.685244                 0.168646   \n",
       " 1      1  44969                  0.657044                 0.154958   \n",
       " 2      2  53740                  0.656672                 0.145773   \n",
       " \n",
       "    prob_of_topic_to_be_first  \n",
       " 0                   0.495474  \n",
       " 1                   0.229848  \n",
       " 2                   0.274678  ,\n",
       " (3,\n",
       "  'second'):    Topic  count  mean_prob_when_second_pos  std_prob_when_second_pos  \\\n",
       " 0      0  96938                   0.685244                  0.168646   \n",
       " 1      1  44969                   0.657044                  0.154958   \n",
       " 2      2  53740                   0.656672                  0.145773   \n",
       " \n",
       "    prob_of_topic_to_be_second  \n",
       " 0                    0.495474  \n",
       " 1                    0.229848  \n",
       " 2                    0.274678  ,\n",
       " (5,\n",
       "  'first'):    Topic  count  mean_prob_when_first_pos  std_prob_when_first_pos  \\\n",
       " 0      0  34196                  0.463955                 0.188842   \n",
       " 1      1  34162                  0.525930                 0.139471   \n",
       " 2      2  71462                  0.643375                 0.146882   \n",
       " 3      3  24651                  0.567807                 0.168798   \n",
       " 4      4  31176                  0.533795                 0.146853   \n",
       " \n",
       "    prob_of_topic_to_be_first  \n",
       " 0                   0.174784  \n",
       " 1                   0.174610  \n",
       " 2                   0.365260  \n",
       " 3                   0.125997  \n",
       " 4                   0.159348  ,\n",
       " (5,\n",
       "  'second'):    Topic  count  mean_prob_when_second_pos  std_prob_when_second_pos  \\\n",
       " 0      0  34196                   0.463955                  0.188842   \n",
       " 1      1  34162                   0.525930                  0.139471   \n",
       " 2      2  71462                   0.643375                  0.146882   \n",
       " 3      3  24651                   0.567807                  0.168798   \n",
       " 4      4  31176                   0.533795                  0.146853   \n",
       " \n",
       "    prob_of_topic_to_be_second  \n",
       " 0                    0.174784  \n",
       " 1                    0.174610  \n",
       " 2                    0.365260  \n",
       " 3                    0.125997  \n",
       " 4                    0.159348  ,\n",
       " (7,\n",
       "  'first'):    Topic  count  mean_prob_when_first_pos  std_prob_when_first_pos  \\\n",
       " 0      0  66552                  0.557567                 0.199313   \n",
       " 1      1  24811                  0.465121                 0.113239   \n",
       " 2      2  25350                  0.554226                 0.167772   \n",
       " 3      3   6703                  0.529954                 0.180145   \n",
       " 4      4   8343                  0.552485                 0.155823   \n",
       " 5      5  54012                  0.544878                 0.149793   \n",
       " 6      6   9876                  0.450720                 0.116870   \n",
       " \n",
       "    prob_of_topic_to_be_first  \n",
       " 0                   0.340164  \n",
       " 1                   0.126815  \n",
       " 2                   0.129570  \n",
       " 3                   0.034261  \n",
       " 4                   0.042643  \n",
       " 5                   0.276069  \n",
       " 6                   0.050479  ,\n",
       " (7,\n",
       "  'second'):    Topic  count  mean_prob_when_second_pos  std_prob_when_second_pos  \\\n",
       " 0      0  66552                   0.557567                  0.199313   \n",
       " 1      1  24811                   0.465121                  0.113239   \n",
       " 2      2  25350                   0.554226                  0.167772   \n",
       " 3      3   6703                   0.529954                  0.180145   \n",
       " 4      4   8343                   0.552485                  0.155823   \n",
       " 5      5  54012                   0.544878                  0.149793   \n",
       " 6      6   9876                   0.450720                  0.116870   \n",
       " \n",
       "    prob_of_topic_to_be_second  \n",
       " 0                    0.340164  \n",
       " 1                    0.126815  \n",
       " 2                    0.129570  \n",
       " 3                    0.034261  \n",
       " 4                    0.042643  \n",
       " 5                    0.276069  \n",
       " 6                    0.050479  ,\n",
       " (9,\n",
       "  'first'):    Topic  count  mean_prob_when_first_pos  std_prob_when_first_pos  \\\n",
       " 0      0  23909                  0.373314                 0.208718   \n",
       " 1      1  24478                  0.519858                 0.158332   \n",
       " 2      2   2819                  0.379913                 0.160531   \n",
       " 3      3   7349                  0.531281                 0.151481   \n",
       " 4      4   5024                  0.432016                 0.130210   \n",
       " 5      5   2518                  0.504390                 0.162038   \n",
       " 6      6  11210                  0.555987                 0.152130   \n",
       " 7      7  47159                  0.484660                 0.122932   \n",
       " 8      8  71181                  0.587882                 0.154299   \n",
       " \n",
       "    prob_of_topic_to_be_first  \n",
       " 0                   0.122205  \n",
       " 1                   0.125113  \n",
       " 2                   0.014409  \n",
       " 3                   0.037563  \n",
       " 4                   0.025679  \n",
       " 5                   0.012870  \n",
       " 6                   0.057297  \n",
       " 7                   0.241041  \n",
       " 8                   0.363824  ,\n",
       " (9,\n",
       "  'second'):    Topic  count  mean_prob_when_second_pos  std_prob_when_second_pos  \\\n",
       " 0      0  23909                   0.373314                  0.208718   \n",
       " 1      1  24478                   0.519858                  0.158332   \n",
       " 2      2   2819                   0.379913                  0.160531   \n",
       " 3      3   7349                   0.531281                  0.151481   \n",
       " 4      4   5024                   0.432016                  0.130210   \n",
       " 5      5   2518                   0.504390                  0.162038   \n",
       " 6      6  11210                   0.555987                  0.152130   \n",
       " 7      7  47159                   0.484660                  0.122932   \n",
       " 8      8  71181                   0.587882                  0.154299   \n",
       " \n",
       "    prob_of_topic_to_be_second  \n",
       " 0                    0.122205  \n",
       " 1                    0.125113  \n",
       " 2                    0.014409  \n",
       " 3                    0.037563  \n",
       " 4                    0.025679  \n",
       " 5                    0.012870  \n",
       " 6                    0.057297  \n",
       " 7                    0.241041  \n",
       " 8                    0.363824  }"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195647"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(96938 + 44969 + 53740)/ 195647 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parsed_Comment</th>\n",
       "      <th>BoW</th>\n",
       "      <th>Topics_from_3</th>\n",
       "      <th>Topics_from_5</th>\n",
       "      <th>Topics_from_7</th>\n",
       "      <th>Topics_from_9</th>\n",
       "      <th>Topics_from_3_first_topic</th>\n",
       "      <th>Topics_from_3_first_topic_prob</th>\n",
       "      <th>Topics_from_3_second_topic</th>\n",
       "      <th>Topics_from_3_second_topic_prob</th>\n",
       "      <th>...</th>\n",
       "      <th>Topics_from_5_second_topic</th>\n",
       "      <th>Topics_from_5_second_topic_prob</th>\n",
       "      <th>Topics_from_7_first_topic</th>\n",
       "      <th>Topics_from_7_first_topic_prob</th>\n",
       "      <th>Topics_from_7_second_topic</th>\n",
       "      <th>Topics_from_7_second_topic_prob</th>\n",
       "      <th>Topics_from_9_first_topic</th>\n",
       "      <th>Topics_from_9_first_topic_prob</th>\n",
       "      <th>Topics_from_9_second_topic</th>\n",
       "      <th>Topics_from_9_second_topic_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Support as co-nom.</td>\n",
       "      <td>[(0, 1), (1, 1)]</td>\n",
       "      <td>[(0, 0.7776697), (1, 0.11116561), (2, 0.111164...</td>\n",
       "      <td>[(2, 0.73288584), (3, 0.06691906), (4, 0.06681...</td>\n",
       "      <td>[(4, 0.7135213), (0, 0.048120014), (2, 0.04775...</td>\n",
       "      <td>[(3, 0.7035975), (8, 0.037089985), (6, 0.03705...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.777670</td>\n",
       "      <td>0</td>\n",
       "      <td>0.777670</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.732886</td>\n",
       "      <td>4</td>\n",
       "      <td>0.713521</td>\n",
       "      <td>4</td>\n",
       "      <td>0.713521</td>\n",
       "      <td>3</td>\n",
       "      <td>0.703597</td>\n",
       "      <td>3</td>\n",
       "      <td>0.703597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Support as nominator.--</td>\n",
       "      <td>[(1, 1), (2, 1)]</td>\n",
       "      <td>[(0, 0.77724415), (1, 0.1113809), (2, 0.111374...</td>\n",
       "      <td>[(2, 0.7325374), (3, 0.067006946), (4, 0.06690...</td>\n",
       "      <td>[(6, 0.38240924), (0, 0.37866765), (2, 0.04782...</td>\n",
       "      <td>[(8, 0.7031383), (6, 0.037113886), (3, 0.03711...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.777244</td>\n",
       "      <td>0</td>\n",
       "      <td>0.777244</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.732537</td>\n",
       "      <td>6</td>\n",
       "      <td>0.382409</td>\n",
       "      <td>6</td>\n",
       "      <td>0.382409</td>\n",
       "      <td>8</td>\n",
       "      <td>0.703138</td>\n",
       "      <td>8</td>\n",
       "      <td>0.703138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support per noms.</td>\n",
       "      <td>[(1, 1), (3, 1)]</td>\n",
       "      <td>[(0, 0.7756807), (1, 0.11258832), (2, 0.111730...</td>\n",
       "      <td>[(2, 0.7326889), (4, 0.06705358), (3, 0.066906...</td>\n",
       "      <td>[(0, 0.714057), (3, 0.04774569), (2, 0.0476620...</td>\n",
       "      <td>[(6, 0.70362055), (8, 0.037078343), (3, 0.0370...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.775681</td>\n",
       "      <td>0</td>\n",
       "      <td>0.775681</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.732689</td>\n",
       "      <td>0</td>\n",
       "      <td>0.714057</td>\n",
       "      <td>0</td>\n",
       "      <td>0.714057</td>\n",
       "      <td>6</td>\n",
       "      <td>0.703621</td>\n",
       "      <td>6</td>\n",
       "      <td>0.703621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Support per noms. BDD is a strong contributor ...</td>\n",
       "      <td>[(1, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1...</td>\n",
       "      <td>[(1, 0.6104352), (0, 0.35598677), (2, 0.033578...</td>\n",
       "      <td>[(0, 0.5629213), (2, 0.3824533), (4, 0.0183045...</td>\n",
       "      <td>[(0, 0.355652), (6, 0.29953256), (5, 0.2928308...</td>\n",
       "      <td>[(1, 0.47300163), (6, 0.2444244), (8, 0.221965...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.610435</td>\n",
       "      <td>1</td>\n",
       "      <td>0.610435</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.562921</td>\n",
       "      <td>0</td>\n",
       "      <td>0.355652</td>\n",
       "      <td>0</td>\n",
       "      <td>0.355652</td>\n",
       "      <td>1</td>\n",
       "      <td>0.473002</td>\n",
       "      <td>1</td>\n",
       "      <td>0.473002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Support, with great pleasure. I work with BDD ...</td>\n",
       "      <td>[(1, 1), (4, 1), (13, 1), (14, 1), (15, 1), (1...</td>\n",
       "      <td>[(0, 0.52742285), (1, 0.45277458), (2, 0.01980...</td>\n",
       "      <td>[(4, 0.6378039), (2, 0.26738784), (0, 0.072630...</td>\n",
       "      <td>[(2, 0.6415359), (6, 0.31867048)]</td>\n",
       "      <td>[(8, 0.49231252), (7, 0.34987646), (4, 0.06488...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.527423</td>\n",
       "      <td>0</td>\n",
       "      <td>0.527423</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.637804</td>\n",
       "      <td>2</td>\n",
       "      <td>0.641536</td>\n",
       "      <td>2</td>\n",
       "      <td>0.641536</td>\n",
       "      <td>8</td>\n",
       "      <td>0.492313</td>\n",
       "      <td>8</td>\n",
       "      <td>0.492313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Parsed_Comment  \\\n",
       "0                                 Support as co-nom.   \n",
       "1                            Support as nominator.--   \n",
       "2                                  Support per noms.   \n",
       "3  Support per noms. BDD is a strong contributor ...   \n",
       "4  Support, with great pleasure. I work with BDD ...   \n",
       "\n",
       "                                                 BoW  \\\n",
       "0                                   [(0, 1), (1, 1)]   \n",
       "1                                   [(1, 1), (2, 1)]   \n",
       "2                                   [(1, 1), (3, 1)]   \n",
       "3  [(1, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1...   \n",
       "4  [(1, 1), (4, 1), (13, 1), (14, 1), (15, 1), (1...   \n",
       "\n",
       "                                       Topics_from_3  \\\n",
       "0  [(0, 0.7776697), (1, 0.11116561), (2, 0.111164...   \n",
       "1  [(0, 0.77724415), (1, 0.1113809), (2, 0.111374...   \n",
       "2  [(0, 0.7756807), (1, 0.11258832), (2, 0.111730...   \n",
       "3  [(1, 0.6104352), (0, 0.35598677), (2, 0.033578...   \n",
       "4  [(0, 0.52742285), (1, 0.45277458), (2, 0.01980...   \n",
       "\n",
       "                                       Topics_from_5  \\\n",
       "0  [(2, 0.73288584), (3, 0.06691906), (4, 0.06681...   \n",
       "1  [(2, 0.7325374), (3, 0.067006946), (4, 0.06690...   \n",
       "2  [(2, 0.7326889), (4, 0.06705358), (3, 0.066906...   \n",
       "3  [(0, 0.5629213), (2, 0.3824533), (4, 0.0183045...   \n",
       "4  [(4, 0.6378039), (2, 0.26738784), (0, 0.072630...   \n",
       "\n",
       "                                       Topics_from_7  \\\n",
       "0  [(4, 0.7135213), (0, 0.048120014), (2, 0.04775...   \n",
       "1  [(6, 0.38240924), (0, 0.37866765), (2, 0.04782...   \n",
       "2  [(0, 0.714057), (3, 0.04774569), (2, 0.0476620...   \n",
       "3  [(0, 0.355652), (6, 0.29953256), (5, 0.2928308...   \n",
       "4                  [(2, 0.6415359), (6, 0.31867048)]   \n",
       "\n",
       "                                       Topics_from_9  \\\n",
       "0  [(3, 0.7035975), (8, 0.037089985), (6, 0.03705...   \n",
       "1  [(8, 0.7031383), (6, 0.037113886), (3, 0.03711...   \n",
       "2  [(6, 0.70362055), (8, 0.037078343), (3, 0.0370...   \n",
       "3  [(1, 0.47300163), (6, 0.2444244), (8, 0.221965...   \n",
       "4  [(8, 0.49231252), (7, 0.34987646), (4, 0.06488...   \n",
       "\n",
       "   Topics_from_3_first_topic  Topics_from_3_first_topic_prob  \\\n",
       "0                          0                        0.777670   \n",
       "1                          0                        0.777244   \n",
       "2                          0                        0.775681   \n",
       "3                          1                        0.610435   \n",
       "4                          0                        0.527423   \n",
       "\n",
       "   Topics_from_3_second_topic  Topics_from_3_second_topic_prob  ...  \\\n",
       "0                           0                         0.777670  ...   \n",
       "1                           0                         0.777244  ...   \n",
       "2                           0                         0.775681  ...   \n",
       "3                           1                         0.610435  ...   \n",
       "4                           0                         0.527423  ...   \n",
       "\n",
       "   Topics_from_5_second_topic  Topics_from_5_second_topic_prob  \\\n",
       "0                           2                         0.732886   \n",
       "1                           2                         0.732537   \n",
       "2                           2                         0.732689   \n",
       "3                           0                         0.562921   \n",
       "4                           4                         0.637804   \n",
       "\n",
       "   Topics_from_7_first_topic  Topics_from_7_first_topic_prob  \\\n",
       "0                          4                        0.713521   \n",
       "1                          6                        0.382409   \n",
       "2                          0                        0.714057   \n",
       "3                          0                        0.355652   \n",
       "4                          2                        0.641536   \n",
       "\n",
       "   Topics_from_7_second_topic  Topics_from_7_second_topic_prob  \\\n",
       "0                           4                         0.713521   \n",
       "1                           6                         0.382409   \n",
       "2                           0                         0.714057   \n",
       "3                           0                         0.355652   \n",
       "4                           2                         0.641536   \n",
       "\n",
       "   Topics_from_9_first_topic  Topics_from_9_first_topic_prob  \\\n",
       "0                          3                        0.703597   \n",
       "1                          8                        0.703138   \n",
       "2                          6                        0.703621   \n",
       "3                          1                        0.473002   \n",
       "4                          8                        0.492313   \n",
       "\n",
       "   Topics_from_9_second_topic  Topics_from_9_second_topic_prob  \n",
       "0                           3                         0.703597  \n",
       "1                           8                         0.703138  \n",
       "2                           6                         0.703621  \n",
       "3                           1                         0.473002  \n",
       "4                           8                         0.492313  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Draft 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Topics_from_3 = df.Topics_from_3.apply(lambda themes_list: [(models[0].show_topic(item[0],topn=15), item[1]) for item in themes_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Topics_from_5 = df.Topics_from_5.apply(lambda themes_list: [(models[1].show_topic(item[0],topn=15), item[1]) for item in themes_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df\u001b[39m.\u001b[39mTopics_from_7 \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mTopics_from_7\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m themes_list: [(models[\u001b[39m2\u001b[39m]\u001b[39m.\u001b[39mshow_topic(item[\u001b[39m0\u001b[39m],topn\u001b[39m=\u001b[39m\u001b[39m15\u001b[39m), item[\u001b[39m1\u001b[39m]) \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m themes_list])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.Topics_from_7 = df.Topics_from_7.apply(lambda themes_list: [(models[2].show_topic(item[0],topn=15), item[1]) for item in themes_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Topics_from_9 = df.Topics_from_9.apply(lambda themes_list: [(models[3].show_topic(item[0],topn=15), item[1]) for item in themes_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([('support', 0.26539585),\n",
       "   ('good', 0.052981544),\n",
       "   ('admin', 0.0238177),\n",
       "   ('user', 0.021110583),\n",
       "   ('editor', 0.018061612),\n",
       "   ('great', 0.017362958),\n",
       "   ('strong', 0.015362159),\n",
       "   ('—', 0.013216087),\n",
       "   ('excellent', 0.010478184),\n",
       "   ('contributor', 0.009782508),\n",
       "   ('seen', 0.008929965),\n",
       "   ('work', 0.008561838),\n",
       "   ('like', 0.008408844),\n",
       "   ('tools', 0.007776866),\n",
       "   ('looks', 0.0075895917)],\n",
       "  0.7776697),\n",
       " ([('oppose', 0.03404599),\n",
       "   ('edits', 0.03332886),\n",
       "   ('wikipedia', 0.019860066),\n",
       "   ('edit', 0.018645601),\n",
       "   ('experience', 0.014715313),\n",
       "   ('good', 0.012932773),\n",
       "   ('admin', 0.0126834065),\n",
       "   ('months', 0.012108943),\n",
       "   ('user', 0.011974941),\n",
       "   ('work', 0.010490522),\n",
       "   ('articles', 0.010187494),\n",
       "   ('time', 0.010005021),\n",
       "   ('need', 0.008791911),\n",
       "   ('like', 0.008295264),\n",
       "   ('article', 0.008207716)],\n",
       "  0.11116561),\n",
       " ([('oppose', 0.025571983),\n",
       "   ('vote', 0.010133443),\n",
       "   ('admin', 0.009774776),\n",
       "   ('user', 0.009733658),\n",
       "   ('think', 0.008607526),\n",
       "   ('neutral', 0.00684812),\n",
       "   ('rfa', 0.0065301857),\n",
       "   ('time', 0.0064934324),\n",
       "   ('like', 0.006048775),\n",
       "   ('page', 0.0055847974),\n",
       "   ('adminship', 0.005446683),\n",
       "   ('people', 0.0052688224),\n",
       "   ('...', 0.004824358),\n",
       "   ('comments', 0.0047361157),\n",
       "   (\"'ve\", 0.00462037)],\n",
       "  0.111164615)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_csv('df_with_topics_v2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draft 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_topics: 3, nb_words: 5\n",
      "nb_topics: 3, nb_words: 10\n",
      "nb_topics: 3, nb_words: 15\n",
      "nb_topics: 5, nb_words: 5\n",
      "nb_topics: 5, nb_words: 10\n",
      "nb_topics: 5, nb_words: 15\n",
      "nb_topics: 7, nb_words: 5\n",
      "nb_topics: 7, nb_words: 10\n",
      "nb_topics: 7, nb_words: 15\n",
      "nb_topics: 9, nb_words: 5\n",
      "nb_topics: 9, nb_words: 10\n",
      "nb_topics: 9, nb_words: 15\n"
     ]
    }
   ],
   "source": [
    "topic_range = range(3, 10, 2)\n",
    "nb_words = 15\n",
    "\n",
    "for nb_topics in topic_range:\n",
    "    print(f\"nb_topics: {nb_topics}, nb_words: {nb_words}\")\n",
    "    current_topics = get_LDA_topics_pipeline(comments_series, num_topics=nb_topics)\n",
    "    with open(f\"nbTopics_{nb_topics}_nbWords_{nb_words}.json\", \"w\") as f:\n",
    "        json.dump(current_topics, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0,\n",
       "  '0.031*\"oppose\" + 0.015*\"edits\" + 0.011*\"admin\" + 0.010*\"user\" + 0.010*\"wikipedia\" + 0.009*\"edit\" + 0.008*\"time\" + 0.008*\"neutral\" + 0.007*\"think\" + 0.007*\"like\"'],\n",
       " [1,\n",
       "  '0.223*\"support\" + 0.049*\"good\" + 0.022*\"admin\" + 0.020*\"user\" + 0.017*\"great\" + 0.016*\"editor\" + 0.014*\"strong\" + 0.014*\"—\" + 0.009*\"contributor\" + 0.009*\"work\"']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"./topic_raw_resuls/nbTopics_2_nbWords_10.json\", \"r\") as file:\n",
    "    topics = json.load(file)\n",
    "topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draft 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['support', 'as', 'co-nom', '.'], ['support', 'as', 'nominator.', '--']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_comments = hlp.tokenize_comments(comments_series)\n",
    "tokenize_comments[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = list(STOPWORDS)\n",
    "tokenize_comments = [[word for word in comment if word not in STOPWORDS] for comment in tokenize_comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "PONCTUATION = string.punctuation\n",
    "tokenize_comments = [[word for word in comment if word not in PONCTUATION] for comment in tokenize_comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['support', 'co-nom'], ['support', 'nominator.', '--']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_comments[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_r = hlp.get_dict_representation(tokenize_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = hlp.get_bow_representation(tokenize_comments,d_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = hlp.init_LDA_model(bow, d_r)\n",
    "topics = hlp.get_LDA_topics(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " '0.221*\"support\" + 0.086*\"--\" + 0.051*\"good\" + 0.024*\"admin\" + 0.021*\"user\" + 0.017*\"editor\" + 0.017*\"great\" + 0.014*\"strong\" + 0.010*\"work\" + 0.010*\"contributor\"')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_3t = topics\n",
    "topics_3t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = hlp.init_LDA_model(bow, d_r, num_topics=6)\n",
    "topics_6t = hlp.get_LDA_topics(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.045*\"n\\'t\" + 0.039*\"\\'s\" + 0.028*\"\\'m\" + 0.022*\"\\'ve\" + 0.022*\"time\" + 0.021*\"support\" + 0.021*\"oppose\" + 0.018*\"neutral\" + 0.017*\"think\" + 0.017*\"vote\"')\n",
      "(1, '0.243*\"support\" + 0.104*\"--\" + 0.062*\"good\" + 0.023*\"editor\" + 0.022*\"admin\" + 0.021*\"great\" + 0.020*\"user\" + 0.018*\"strong\" + 0.013*\"work\" + 0.012*\"contributor\"')\n",
      "(2, '0.024*\"\\'s\" + 0.019*\"oppose\" + 0.014*\"``\" + 0.012*\"user\" + 0.011*\"page\" + 0.011*\"wikipedia\" + 0.007*\"articles\" + 0.007*\"talk\" + 0.006*\"admin\" + 0.005*\"users\"')\n",
      "(3, '0.255*\"\\'\\'\" + 0.058*\"font\" + 0.036*\"support\" + 0.029*\"color=\" + 0.028*\"style=\" + 0.026*\"small\" + 0.019*\"vandal\" + 0.018*\"—\" + 0.018*\"span\" + 0.014*\"``\"')\n",
      "(4, '0.069*\"support\" + 0.040*\"tools\" + 0.037*\"admin\" + 0.035*\"user\" + 0.031*\"reason\" + 0.027*\"n\\'t\" + 0.024*\"use\" + 0.023*\"--\" + 0.019*\"abuse\" + 0.014*\"big\"')\n",
      "(5, '0.051*\"oppose\" + 0.046*\"edits\" + 0.026*\"edit\" + 0.020*\"--\" + 0.020*\"experience\" + 0.016*\"wikipedia\" + 0.014*\"n\\'t\" + 0.012*\"months\" + 0.011*\"user\" + 0.011*\"admin\"')\n"
     ]
    }
   ],
   "source": [
    "for topic in topics_6t:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = hlp.init_LDA_model(bow, d_r, num_topics=9)\n",
    "topics_9t = hlp.get_LDA_topics(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.284*\"support\" + 0.110*\"--\" + 0.073*\"good\" + 0.025*\"editor\" + 0.023*\"great\" + 0.021*\"user\" + 0.020*\"strong\" + 0.019*\"admin\" + 0.014*\"excellent\" + 0.013*\"work\"')\n",
      "(1, '0.059*\"edits\" + 0.050*\"oppose\" + 0.033*\"edit\" + 0.021*\"user\" + 0.021*\"months\" + 0.020*\"--\" + 0.020*\"talk\" + 0.020*\"n\\'t\" + 0.017*\"neutral\" + 0.014*\"page\"')\n",
      "(2, '0.042*\"wikipedia\" + 0.024*\"good\" + 0.024*\"admin\" + 0.023*\"work\" + 0.021*\"articles\" + 0.016*\"experience\" + 0.015*\"need\" + 0.013*\"admins\" + 0.013*\"policy\" + 0.011*\"contributions\"')\n",
      "(3, '0.065*\"yes\" + 0.060*\"vandal\" + 0.031*\"wikipedian\" + 0.025*\"nominate\" + 0.020*\"fighter\" + 0.017*\"sans\" + 0.016*\"p\" + 0.015*\"ms\" + 0.013*\"comic\" + 0.012*\"worthy\"')\n",
      "(4, '0.296*\"\\'\\'\" + 0.067*\"font\" + 0.047*\"support\" + 0.034*\"color=\" + 0.033*\"summaries\" + 0.032*\"style=\" + 0.021*\"span\" + 0.020*\"--\" + 0.016*\"—\" + 0.015*\"s\"')\n",
      "(5, '0.128*\"oppose\" + 0.045*\"--\" + 0.019*\"afd\" + 0.018*\"wp\" + 0.017*\"namespace\" + 0.014*\"reasons\" + 0.014*\"concerns\" + 0.013*\"deletion\" + 0.011*\"agree\" + 0.011*\"delete\"')\n",
      "(6, '0.041*\"\\'s\" + 0.025*\"n\\'t\" + 0.015*\"``\" + 0.014*\"\\'m\" + 0.014*\"oppose\" + 0.013*\"vote\" + 0.011*\"think\" + 0.010*\"admin\" + 0.010*\"rfa\" + 0.008*\"time\"')\n",
      "(7, '0.064*\"support\" + 0.043*\"small\" + 0.029*\"utc\" + 0.026*\"positive\" + 0.023*\"project\" + 0.021*\"sup\" + 0.018*\"benefit\" + 0.018*\"irc\" + 0.018*\"lucky\" + 0.014*\"talk\"')\n",
      "(8, '0.102*\"support\" + 0.053*\"n\\'t\" + 0.049*\"admin\" + 0.032*\"tools\" + 0.029*\"user\" + 0.027*\"--\" + 0.025*\"...\" + 0.025*\"reason\" + 0.019*\"\\'s\" + 0.018*\"use\"')\n"
     ]
    }
   ],
   "source": [
    "for topic in topics_9t:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = hlp.init_LDA_model(bow, d_r, num_topics=15)\n",
    "topics_9t = hlp.get_LDA_topics(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.219*\"good\" + 0.155*\"support\" + 0.058*\"work\" + 0.041*\"yes\" + 0.037*\"editor\" + 0.034*\"contributions\" + 0.029*\"nom\" + 0.019*\"happy\" + 0.018*\"record\" + 0.017*\"luck\"')\n",
      "(1, '0.034*\"agree\" + 0.029*\"strongly\" + 0.025*\"pov\" + 0.023*\"absolutely\" + 0.019*\"personal\" + 0.018*\"extreme\" + 0.017*\"changed\" + 0.017*\"comment\" + 0.014*\"possible\" + 0.014*\"nominee\"')\n",
      "(2, '0.078*\"edit\" + 0.063*\"summaries\" + 0.060*\"questions\" + 0.056*\"answers\" + 0.027*\"use\" + 0.023*\"sup\" + 0.022*\"history\" + 0.018*\"policy\" + 0.011*\"fair\" + 0.011*\"sense\"')\n",
      "(3, '0.056*\"vandal\" + 0.046*\"wikipedia\" + 0.043*\"new\" + 0.027*\"speedy\" + 0.025*\"deletion\" + 0.022*\"articles\" + 0.022*\"criteria\" + 0.018*\"fighter\" + 0.017*\"image\" + 0.016*\"deleted\"')\n",
      "(4, '0.113*\"—\" + 0.108*\"support\" + 0.079*\"\\'m\" + 0.071*\"sure\" + 0.040*\"\\'ll\" + 0.026*\"–\" + 0.017*\"lucky\" + 0.017*\"2005\" + 0.014*\"impressed\" + 0.012*\"soon\"')\n",
      "(5, '0.079*\"n\\'t\" + 0.067*\"\\'s\" + 0.032*\"support\" + 0.022*\"admin\" + 0.022*\"think\" + 0.016*\"vote\" + 0.015*\"like\" + 0.015*\"...\" + 0.014*\"\\'m\" + 0.013*\"rfa\"')\n",
      "(6, '0.039*\"oppose\" + 0.024*\"wikipedia\" + 0.018*\"admin\" + 0.016*\"n\\'t\" + 0.015*\"\\'s\" + 0.015*\"--\" + 0.014*\"good\" + 0.013*\"like\" + 0.013*\"edit\" + 0.013*\"experience\"')\n",
      "(7, '0.351*\"support\" + 0.184*\"--\" + 0.055*\"good\" + 0.033*\"great\" + 0.030*\"admin\" + 0.029*\"strong\" + 0.025*\"editor\" + 0.023*\"user\" + 0.020*\"like\" + 0.019*\"excellent\"')\n",
      "(8, '0.205*\"``\" + 0.163*\"\\'\\'\" + 0.023*\"vandals\" + 0.018*\"utc\" + 0.010*\"p\" + 0.008*\"voted\" + 0.008*\"...\" + 0.008*\"force\" + 0.007*\"guess\" + 0.007*\"days\"')\n",
      "(9, '0.090*\"articles\" + 0.068*\"article\" + 0.044*\"wp\" + 0.036*\"afd\" + 0.027*\"summary\" + 0.022*\"content\" + 0.020*\"irc\" + 0.018*\"work\" + 0.016*\"topics\" + 0.016*\"writing\"')\n",
      "(10, '0.217*\"oppose\" + 0.080*\"--\" + 0.051*\"neutral\" + 0.025*\"vote\" + 0.022*\"experience\" + 0.021*\"question\" + 0.021*\"concerns\" + 0.021*\"weak\" + 0.019*\"reasons\" + 0.018*\"answer\"')\n",
      "(11, '0.173*\"edits\" + 0.080*\"talk\" + 0.079*\"user\" + 0.062*\"page\" + 0.021*\"pages\" + 0.020*\"months\" + 0.017*\"edit\" + 0.017*\"article\" + 0.016*\"space\" + 0.015*\"wikipedia\"')\n",
      "(12, '0.094*\"support\" + 0.057*\"admin\" + 0.053*\"tools\" + 0.039*\"user\" + 0.029*\"use\" + 0.026*\"abuse\" + 0.017*\"trust\" + 0.016*\"editor\" + 0.016*\"wikipedia\" + 0.014*\"good\"')\n",
      "(13, '0.281*\"\\'\\'\" + 0.097*\"font\" + 0.054*\"support\" + 0.049*\"color=\" + 0.047*\"style=\" + 0.030*\"small\" + 0.030*\"span\" + 0.025*\"s\" + 0.024*\"--\" + 0.017*\"background\"')\n",
      "(14, '0.129*\"\\'ve\" + 0.093*\"support\" + 0.087*\"seen\" + 0.035*\"time\" + 0.030*\"nominator\" + 0.026*\"\\'s\" + 0.026*\"work\" + 0.025*\"cool\" + 0.023*\"lot\" + 0.014*\"mop\"')\n"
     ]
    }
   ],
   "source": [
    "for topic in topics_9t:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "topcis_3t_pipeline = get_LDA_topics_pipeline(comments_series, num_topics=3, ponctuation=True, stopwords=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.159*\"\\'\\'\" + 0.085*\"support\" + 0.045*\"--\" + 0.036*\"font\" + 0.025*\"``\" + 0.024*\"—\" + 0.018*\"color=\" + 0.018*\"style=\" + 0.016*\"looks\" + 0.016*\"small\"')\n",
      "(1, '0.033*\"oppose\" + 0.024*\"n\\'t\" + 0.020*\"\\'s\" + 0.014*\"edits\" + 0.009*\"user\" + 0.009*\"wikipedia\" + 0.009*\"time\" + 0.009*\"admin\" + 0.008*\"\\'m\" + 0.008*\"neutral\"')\n",
      "(2, '0.173*\"support\" + 0.066*\"--\" + 0.056*\"good\" + 0.027*\"admin\" + 0.023*\"user\" + 0.020*\"editor\" + 0.015*\"great\" + 0.013*\"work\" + 0.012*\"strong\" + 0.010*\"seen\"')\n"
     ]
    }
   ],
   "source": [
    "for topic in topcis_3t_pipeline:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "topcis_3t_pipeline = get_LDA_topics_pipeline(comments_series, num_topics=3, ponctuation=True, stopwords=True, fine_tune_stopwords=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.024*\"oppose\" + 0.016*\"edits\" + 0.012*\"wikipedia\" + 0.011*\"admin\" + 0.011*\"user\" + 0.009*\"edit\" + 0.009*\"time\" + 0.008*\"\\'m\" + 0.008*\"think\" + 0.007*\"like\"')\n",
      "(1, '0.063*\"oppose\" + 0.022*\"—\" + 0.020*\"questions\" + 0.019*\"small\" + 0.019*\"answers\" + 0.013*\"span\" + 0.013*\"neutral\" + 0.013*\"answer\" + 0.011*\"solid\" + 0.011*\"s\"')\n",
      "(2, '0.266*\"support\" + 0.057*\"good\" + 0.027*\"admin\" + 0.024*\"user\" + 0.020*\"great\" + 0.020*\"editor\" + 0.016*\"strong\" + 0.011*\"work\" + 0.011*\"contributor\" + 0.010*\"excellent\"')\n"
     ]
    }
   ],
   "source": [
    "for topic in topcis_3t_pipeline:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "topcis_3t_pipeline = get_LDA_topics_pipeline(comments_series, num_topics=3, ponctuation=True, stopwords=True, fine_tune_stopwords=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.035*\"oppose\" + 0.024*\"edits\" + 0.018*\"admin\" + 0.014*\"time\" + 0.014*\"wikipedia\" + 0.014*\"edit\" + 0.012*\"neutral\" + 0.012*\"good\" + 0.011*\"experience\" + 0.010*\"user\"')\n",
      "(1, '0.020*\"oppose\" + 0.012*\"page\" + 0.011*\"user\" + 0.010*\"vote\" + 0.008*\"talk\" + 0.006*\"...\" + 0.006*\"articles\" + 0.005*\"people\" + 0.005*\"wikipedia\" + 0.005*\"comments\"')\n",
      "(2, '0.269*\"support\" + 0.053*\"good\" + 0.025*\"admin\" + 0.021*\"user\" + 0.018*\"editor\" + 0.018*\"great\" + 0.016*\"strong\" + 0.013*\"—\" + 0.011*\"excellent\" + 0.010*\"work\"')\n"
     ]
    }
   ],
   "source": [
    "for topic in topcis_3t_pipeline:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_6t_pipeline = get_LDA_topics_pipeline(comments_series, num_topics=6, ponctuation=True, stopwords=True, fine_tune_stopwords=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.074*\"oppose\" + 0.057*\"edits\" + 0.042*\"edit\" + 0.028*\"talk\" + 0.028*\"user\" + 0.025*\"page\" + 0.012*\"months\" + 0.010*\"vandalism\" + 0.009*\"vandal\" + 0.009*\"count\"')\n",
      "(1, '0.270*\"support\" + 0.071*\"good\" + 0.032*\"user\" + 0.032*\"admin\" + 0.025*\"editor\" + 0.021*\"great\" + 0.014*\"contributor\" + 0.013*\"excellent\" + 0.012*\"seen\" + 0.012*\"like\"')\n",
      "(2, '0.036*\"yes\" + 0.018*\"color\" + 0.016*\"agree\" + 0.015*\"red\" + 0.013*\"green\" + 0.012*\"sam\" + 0.012*\"oh\" + 0.009*\"withdraw\" + 0.008*\"background\" + 0.007*\"e\"')\n",
      "(3, '0.032*\"wikipedia\" + 0.020*\"admin\" + 0.017*\"good\" + 0.016*\"time\" + 0.015*\"experience\" + 0.014*\"work\" + 0.014*\"oppose\" + 0.014*\"articles\" + 0.013*\"need\" + 0.012*\"like\"')\n",
      "(4, '0.028*\"oppose\" + 0.015*\"vote\" + 0.011*\"neutral\" + 0.011*\"admin\" + 0.010*\"think\" + 0.009*\"user\" + 0.009*\"rfa\" + 0.008*\"adminship\" + 0.007*\"like\" + 0.007*\"comments\"')\n",
      "(5, '0.171*\"support\" + 0.038*\"—\" + 0.030*\"...\" + 0.028*\"strong\" + 0.021*\"thought\" + 0.021*\"course\" + 0.016*\"answers\" + 0.015*\"questions\" + 0.015*\"nominator\" + 0.014*\"nom\"')\n"
     ]
    }
   ],
   "source": [
    "for topic in topics_6t_pipeline:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "print(type(topics_6t_pipeline))\n",
    "print(type(topics_6t_pipeline[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test.json\", \"w\") as file:\n",
    "    json.dump(topics_6t_pipeline, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test.json\", \"r\") as file:\n",
    "    topics_6t_read = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0,\n",
       "  '0.074*\"oppose\" + 0.057*\"edits\" + 0.042*\"edit\" + 0.028*\"talk\" + 0.028*\"user\" + 0.025*\"page\" + 0.012*\"months\" + 0.010*\"vandalism\" + 0.009*\"vandal\" + 0.009*\"count\"'],\n",
       " [1,\n",
       "  '0.270*\"support\" + 0.071*\"good\" + 0.032*\"user\" + 0.032*\"admin\" + 0.025*\"editor\" + 0.021*\"great\" + 0.014*\"contributor\" + 0.013*\"excellent\" + 0.012*\"seen\" + 0.012*\"like\"'],\n",
       " [2,\n",
       "  '0.036*\"yes\" + 0.018*\"color\" + 0.016*\"agree\" + 0.015*\"red\" + 0.013*\"green\" + 0.012*\"sam\" + 0.012*\"oh\" + 0.009*\"withdraw\" + 0.008*\"background\" + 0.007*\"e\"'],\n",
       " [3,\n",
       "  '0.032*\"wikipedia\" + 0.020*\"admin\" + 0.017*\"good\" + 0.016*\"time\" + 0.015*\"experience\" + 0.014*\"work\" + 0.014*\"oppose\" + 0.014*\"articles\" + 0.013*\"need\" + 0.012*\"like\"'],\n",
       " [4,\n",
       "  '0.028*\"oppose\" + 0.015*\"vote\" + 0.011*\"neutral\" + 0.011*\"admin\" + 0.010*\"think\" + 0.009*\"user\" + 0.009*\"rfa\" + 0.008*\"adminship\" + 0.007*\"like\" + 0.007*\"comments\"'],\n",
       " [5,\n",
       "  '0.171*\"support\" + 0.038*\"—\" + 0.030*\"...\" + 0.028*\"strong\" + 0.021*\"thought\" + 0.021*\"course\" + 0.016*\"answers\" + 0.015*\"questions\" + 0.015*\"nominator\" + 0.014*\"nom\"']]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_6t_read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Done with old version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " '0.144*\".\" + 0.135*\"support\" + 0.052*\"--\" + 0.033*\",\" + 0.029*\"good\" + 0.022*\"a\" + 0.019*\"-\" + 0.017*\"!\" + 0.015*\"and\" + 0.013*\"admin\"')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_3t = topics\n",
    "topics_3t[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Done with old version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_pipeline_6t = get_LDA_topics_pipeline(comments_series, num_topics=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " '0.065*\".\" + 0.043*\",\" + 0.040*\"and\" + 0.035*\"he\" + 0.033*\"a\" + 0.028*\"the\" + 0.026*\"i\" + 0.025*\"support\" + 0.023*\"to\" + 0.020*\"his\"')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_pipeline_6t[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Done with old version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_pipeline_9t = get_LDA_topics_pipeline(comments_series, num_topics=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " '0.079*\".\" + 0.049*\"of\" + 0.048*\",\" + 0.041*\"edits\" + 0.039*\"oppose\" + 0.035*\"and\" + 0.023*\"in\" + 0.017*\"a\" + 0.016*\"wikipedia\" + 0.016*\"experience\"')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_pipeline_9t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/thetorf/anaconda3/envs/ada/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_72223/1189724256.py\", line 1, in <module>\n",
      "    topics_pipeline_3t_ws = get_LDA_topics_pipeline(comments_series, num_topics=3)\n",
      "  File \"/home/thetorf/Documents/epfl/MA1.2/ada/project-wikiRfA/ada-2023-project-abracadabra/P3_helpers.py\", line 374, in get_LDA_topics_pipeline\n",
      "    dictionary.filter_tokens(bad_ids=[dictionary.token2id[word] for word in STOPWORDS])\n",
      "  File \"/home/thetorf/Documents/epfl/MA1.2/ada/project-wikiRfA/ada-2023-project-abracadabra/P3_helpers.py\", line 374, in <listcomp>\n",
      "    dictionary.filter_tokens(bad_ids=[dictionary.token2id[word] for word in STOPWORDS])\n",
      "KeyError: 'ltd'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/thetorf/anaconda3/envs/ada/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2120, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/home/thetorf/anaconda3/envs/ada/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/home/thetorf/anaconda3/envs/ada/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/home/thetorf/anaconda3/envs/ada/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/home/thetorf/anaconda3/envs/ada/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"/home/thetorf/anaconda3/envs/ada/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"/home/thetorf/anaconda3/envs/ada/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "  File \"/home/thetorf/anaconda3/envs/ada/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/thetorf/anaconda3/envs/ada/lib/python3.9/site-packages/stack_data/core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/home/thetorf/anaconda3/envs/ada/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/thetorf/anaconda3/envs/ada/lib/python3.9/site-packages/stack_data/core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/home/thetorf/anaconda3/envs/ada/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/thetorf/anaconda3/envs/ada/lib/python3.9/site-packages/stack_data/core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "  File \"/home/thetorf/anaconda3/envs/ada/lib/python3.9/site-packages/executing/executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "topics_pipeline_3t_ws = get_LDA_topics_pipeline(comments_series, num_topics=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'topics_pipeline_3t_ws' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m topics_pipeline_3t_ws[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'topics_pipeline_3t_ws' is not defined"
     ]
    }
   ],
   "source": [
    "topics_pipeline_3t_ws[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
