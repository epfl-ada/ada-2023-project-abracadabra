{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import mwparserfromhell\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data\n",
    "\n",
    "And correct some date inconcistencies\n",
    "\n",
    "### From early version of Emma's code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file into a list of lines\n",
    "with open('wiki-RfA.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Create a list of dictionaries, where each dictionary represents a record\n",
    "df = []\n",
    "current_entry = {}\n",
    "\n",
    "# Iterate through each line, current_entry = one log entry with all columns, df = list of all votee/voter pairs\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    if line:\n",
    "        key, value = line.split(':', 1)\n",
    "        current_entry[key] = value\n",
    "    else:\n",
    "        df.append(current_entry)\n",
    "        current_entry = {}\n",
    "\n",
    "# Append  last record\n",
    "if current_entry:\n",
    "    df.append(current_entry)\n",
    "\n",
    "# Convert into DataFrame and store in csv\n",
    "df = pd.DataFrame(df)\n",
    "df.columns = ['Source', 'Target', 'Vote', 'Results', 'Year', 'Date', 'Comment']\n",
    "\n",
    "df.to_csv('wiki-RfA.csv')\n",
    "\n",
    "# Set Nan values\n",
    "# replace field that's entirely space (or empty) with NaN\n",
    "df.replace(r'^\\s*$', np.nan, regex=True, inplace=True)\n",
    "\n",
    "# replace inconsistent date\n",
    "df['Date'] = df['Date'].str.replace('Julu ', 'July ')\n",
    "df['Date'] = df['Date'].str.replace('Janry ', 'January ')\n",
    "df['Date'] = df['Date'].str.replace('Mya ', 'May ')\n",
    "df['Date'] = df['Date'].str.replace('Jan ', 'January ')\n",
    "df['Date'] = df['Date'].str.replace('Feb ', 'February ')\n",
    "df['Date'] = df['Date'].str.replace('Mar ', 'March ')\n",
    "df['Date'] = df['Date'].str.replace('Apr ', 'April ')\n",
    "df['Date'] = df['Date'].str.replace('Jun ', 'June ')\n",
    "df['Date'] = df['Date'].str.replace('Jul ', 'July ')\n",
    "df['Date'] = df['Date'].str.replace('Aug ', 'August ')\n",
    "df['Date'] = df['Date'].str.replace('Sep ', 'September ')\n",
    "df['Date'] = df['Date'].str.replace('Oct ', 'October ')\n",
    "df['Date'] = df['Date'].str.replace('Nov ', 'November ')\n",
    "df['Date'] = df['Date'].str.replace('Dec ', 'December ')\n",
    "\n",
    "# Convert Date to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%H:%M, %d %B %Y', errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adds to do (OLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Year = df.Year.astype('Int64')\n",
    "df.Comment = df.Comment.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Extraction from Comments\n",
    "\n",
    "First create a parsed column with only text infromation from Wikitext (markup language) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Parsed_Comment\"] = df.Comment.apply(lambda x: mwparserfromhell.parse(x).strip_code())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf_matrix(comments):\n",
    "    # Create the TF-IDF matrix\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', max_features= 5000)\n",
    "    tfidf_matrix = vectorizer.fit_transform(comments.values())\n",
    "    return tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idx_lower_bound(keys):\n",
    "    keys = [item[1] for item in keys]\n",
    "    lower = min(keys)\n",
    "    return lower\n",
    "\n",
    "def get_idx_upper_bound(keys):\n",
    "    keys = [item[1] for item in keys]\n",
    "    upper = max(keys)\n",
    "    return upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group by Target\n",
    "grouped_by_target = df.groupby('Target').apply(lambda x: list((enumerate(zip(x['Source'], x['Parsed_Comment'])))))\n",
    "grouped_by_target = grouped_by_target.apply(lambda x: [(item[1][0], item[0], item[1][1]) for item in x]).reset_index()\n",
    "grouped_by_target = grouped_by_target.rename(columns={0:'Text'})\n",
    "\n",
    "#Build UID for all pairs of (SRC, Comment)\n",
    "global_index = 0\n",
    "for df_index, row in grouped_by_target.iterrows():\n",
    "    length_of_current_list = len(row.Text)\n",
    "    mrange = range(global_index, global_index+length_of_current_list)\n",
    "    global_index += length_of_current_list\n",
    "    new_list = [(item[0], idx, item[2]) for item, idx in zip(row.Text, mrange)]\n",
    "    grouped_by_target.at[df_index, 'Text'] = new_list\n",
    "\n",
    "#Format to have dictionary to be sure to access things in the right order\n",
    "grouped_by_target.Text = grouped_by_target.Text.apply(lambda x: {(item[0], item[1]):item[2] for item in x})\n",
    "\n",
    "#Extracting and flattening of the comments with UID \n",
    "comments_list = [row.Text for _, row in  grouped_by_target.iterrows()]\n",
    "comments_dict = {}\n",
    "for d in comments_list:\n",
    "    comments_dict.update(d)\n",
    "\n",
    "#Compute the tfidf coefficient building the vectors\n",
    "tfidf_m_sparse = tf_idf_matrix(comments_dict)\n",
    "\n",
    "#Reformat the output to be normaly indexable (no need to optimize with sparse matrix)\n",
    "tfidf_m =  tfidf_m_sparse.todense()\n",
    "\n",
    "#Match the tfidf vectors to corresponding vectors\n",
    "grouped_by_target['tfidf_matrix'] = grouped_by_target.Text.apply(lambda x: tfidf_m[get_idx_lower_bound(x.keys()):get_idx_upper_bound(x.keys())+1])\n",
    "\n",
    "#Compute the cosinus similarity\n",
    "new_rows = []\n",
    "for index_df, row in grouped_by_target.iterrows():\n",
    "    target_tfidf_dense_matrix = np.asarray(row.tfidf_matrix)\n",
    "    target_cos_sim = cosine_similarity(target_tfidf_dense_matrix, target_tfidf_dense_matrix)\n",
    "    new_rows.append(target_cos_sim)\n",
    "grouped_by_target[\"cosinus_similarity\"] = new_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_target.to_csv(\"CosinusSimByTarget.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work in progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosinus_sims = []\n",
    "for i in range(25*7):\n",
    "    cosinus_sims.append(np.load(f\"working_dir/cosine_sim_{i}_batch.npy\"))\n",
    "    len(cosinus_sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Looks good.  --'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[176233].Comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_year = df['Year'].max()\n",
    "min_year = df['Year'].min()\n",
    "mean_year = df['Year'].mean()\n",
    "\n",
    "print(f\"max_year: {max_year}\\n min_year: {min_year}\\n mean_year: {mean_year}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Obsolete\n",
    "\n",
    "df.Comment = df.Comment.astype('str')\n",
    "\n",
    "def getting_tags_number(comment):\n",
    "    if \"'''\" in comment:\n",
    "        return len(comment.split(\"'''\")) - 2\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def getting_tags_list(comment):\n",
    "    if \"'''\" in comment[:4]:\n",
    "        text = comment.split(\"'''\")[1]\n",
    "        if len(text.split(\" \")) > 5:\n",
    "            return text\n",
    "        else:   \n",
    "            return \"\"\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "df[\"CommentTags\"] = df.Comment.apply(getting_tags_list)\n",
    "df[\"NumberCommentTag\"] = df.Comment.apply(getting_tags_number)\n",
    "\n",
    "for t in df.CommentTags.unique()[250:270]:\n",
    "    print(t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
